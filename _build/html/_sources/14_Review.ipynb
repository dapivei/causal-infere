{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dapivei/causal-infere/blob/main/sections/14_Review.ipynb)\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "MKfKn7BANzBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{array}{c}\n",
        "\\textbf{Final Course Review}\\\\\\\\\n",
        "\\textbf{Daniela Pinto Veizaga, Xiang Pan, and Xiang Gao} \\\\\n",
        "\\textit{Center for Data Science, New York University} \\\\\\\\\\\\\n",
        "\\textit{December 11, 2024}\n",
        "\\end{array}\n",
        "$$\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RYfCRqJ-LAj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Goals For Today\n",
        "\n",
        "1. Review some selected problems from past homework/midterm.\n",
        "2. Review some selected proofs from lectures.\n"
      ],
      "metadata": {
        "id": "TbSgQ3hpbrtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Selected Problems"
      ],
      "metadata": {
        "id": "NGrNdhnSmUMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1 (PS3 Q3)"
      ],
      "metadata": {
        "id": "MDiH-d8cnHCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have a linear causal model, and treatment is independent of other causes\n",
        "(as in the case of a perfect experiment), then linear regression will estimate\n",
        "the linear, causal effect of $S$ on $Y$.\n",
        "\n",
        "However, now let us suppose that a medical researcher does an experiment\n",
        "assigning different dosage levels of a drug, $D$, to see how dosage affects pain level $P$. The drug can have many dosage levels, so we think of it as a continuous variable. The true causal model, in real life, is\n",
        "\n",
        "$$\n",
        "P(D, U) = \\gamma_1 D + \\gamma_2 D^2 + U\n",
        "$$\n",
        "\n",
        "That is, the drug's effect has a linear component, $\\gamma_1 D$; a non-linear component, $\\gamma_2 D^2$; and an idiosyncratic component $U$.\n",
        "\n",
        "The researcher naively runs a typical linear regression of the form\n",
        "$$\n",
        "P = \\alpha_0 + \\alpha_1 D + U\n",
        "$$\n",
        "Because it is an experiment, we can assume $U \\perp D$. Thus, the researcher's regression model will identify:\n",
        "$$\n",
        "\\alpha_1 = \\frac{\\text{Cov}(P, D)}{\\text{Var}(D)}\n",
        "$$\n",
        "\n",
        "Show, by plugging the true causal model into the above expression and using properties of the covariance, that the researcher’s regression model will estimate $\\gamma_1$ plus something else."
      ],
      "metadata": {
        "id": "LPltfv9lxKYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOLUTION:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\alpha_1 &= \\frac{\\text{Cov}(P, D)}{\\text{Var}(D)} \\\\\n",
        "&= \\frac{\\text{Cov}(\\gamma_1 D + \\gamma_2 D^2 + U, D)}{\\text{Var}(D)} \\\\\n",
        "&= \\frac{\\text{Cov}(\\gamma_1 D, D) + \\text{Cov}(\\gamma_2 D^2, D) + \\text{Cov}(U, D)}{\\text{Var}(D)} \\quad \\text{(Prop of cov.)} \\\\\n",
        "&= \\frac{\\gamma_1 \\text{Cov}(D, D) + \\gamma_2 \\text{Cov}(D^2, D) + 0}{\\text{Var}(D)} \\quad \\text{(Prop of cov. + $U \\perp D$)} \\\\\n",
        "&= \\frac{\\gamma_1 \\text{Var}(D) + \\gamma_2 \\text{Cov}(D^2, D)}{\\text{Var}(D)} \\\\\n",
        "&= \\gamma_1 + \\gamma_2 \\frac{\\text{Cov}(D^2, D)}{\\text{Var}(D)}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "oBZi2mZXyJso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tells us even if we can identify the causal parameter, we can still have estimation errors from model misspecification.\n",
        "\n",
        "See another example PS4 Q2."
      ],
      "metadata": {
        "id": "JyUbJD76zRaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2 (Practice Midterm Q6)"
      ],
      "metadata": {
        "id": "eyPrVqEexKd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show, working from the definition of variance and using properties of expectations, that\n",
        "$$\n",
        "\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X, Y)\n",
        "$$\n",
        "Justify all steps (excluding simple algebra)."
      ],
      "metadata": {
        "id": "4Hx7hYSJxMrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\n",
        "\\text{Var}(X + Y) &= \\mathbb{E}[(X + Y - \\mathbb{E}[X + Y])^2] \\\\\n",
        "&= \\mathbb{E}[(X + Y - \\mathbb{E}[X] - \\mathbb{E}[Y])^2] \\quad \\text{(prop. of expec.)} \\\\\n",
        "&= \\mathbb{E}[((X - \\mathbb{E}[X]) + (Y - \\mathbb{E}[Y]))^2] \\\\\n",
        "&= \\mathbb{E}[(X - \\mathbb{E}[X])^2 + (Y - \\mathbb{E}[Y])^2 + 2(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] \\\\\n",
        "&= \\mathbb{E}[(X - \\mathbb{E}[X])^2] + \\mathbb{E}[(Y - \\mathbb{E}[Y])^2] + 2\\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] \\quad \\text{(prop. of expec.)} \\\\\n",
        "&= \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X, Y)\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "QbDW5JWS5-dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem 2.1 (Midterm Q6)"
      ],
      "metadata": {
        "id": "qdrh6i3r5kDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show, working from the definition of variance and using properties of expectations, that\n",
        "$$\n",
        "\\text{Var}(a + bX) = b^2 \\text{Var}(X)\n",
        "$$\n",
        "Justify all steps (excluding simple algebra). (Hint: use the first given definition of variance)."
      ],
      "metadata": {
        "id": "KsEtmdTD5s6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\n",
        "\\text{Var}(a + bX) &= \\mathbb{E}[(a + bX - \\mathbb{E}[a + bX])^2] \\\\\n",
        "&= \\mathbb{E}[(a + bX - \\mathbb{E}[a] - b\\mathbb{E}[X])^2] \\quad \\text{(prop. of exp.)} \\\\\n",
        "&= \\mathbb{E}[(a + bX - a - b\\mathbb{E}[X])^2] \\quad \\text{(prop. of exp.)} \\\\\n",
        "&= \\mathbb{E}[b^2 (X - \\mathbb{E}[X])^2] \\\\\n",
        "&= b^2 \\mathbb{E}[(X - \\mathbb{E}[X])^2] \\quad \\text{(prop. of exp.)} \\\\\n",
        "&= b^2 \\text{Var}(X)\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "zpCl-lMP8xf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3 (PS4 Q3)"
      ],
      "metadata": {
        "id": "HCxwa1Rz1FnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we identify the ATE using the matching estimator under the conditional independence assumption?\n",
        "\n",
        "Suppose we have a single control variable, $C$, that takes on $k$\n",
        "values, $c_1, \\dots, c_k$. Show, using the LIE, that\n",
        "$$\n",
        "\\text{ATE} = \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U)] =\n",
        "\\sum_{i=1}^k \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid C = c_i]P(C = c_i)\n",
        "$$"
      ],
      "metadata": {
        "id": "SBq67G9o1HNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This result follows from the LIE and the definition of the expectation of a random variable:\n",
        "\\begin{align*}\n",
        "\\text{ATE} &= \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U)] \\\\\n",
        "&= \\mathbb{E}[\\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid C]] \\quad \\text{(LIE)} \\\\\n",
        "&= \\sum_{i=1}^k \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid C = c_i]P(C = c_i)\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "RlQX1wEMw3PZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, assuming that $S \\perp U \\mid C$, show that\n",
        "$$\n",
        "\\text{ATE} = \\sum_{i=1}^k \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid C = c_i]P(C = c_i)\n",
        "$$\n",
        "$$\n",
        "= \\sum_{i=1}^k \\left(\\mathbb{E}[Y(S = 1, U) \\mid C = c_i, S = 1] - \\mathbb{E}[Y(S = 0, U) \\mid C = c_i, S = 0]\\right)P(C = c_i)\n",
        "$$\n",
        "\n",
        "Every term in the second line is estimable from data, implying that the ATE is identified. Indeed, this is the parameter equivalent of $\\widehat{\\text{ATE}}_m$ from the lecture slides."
      ],
      "metadata": {
        "id": "HBe4IdWgxtsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part is actually quite similar to showing that an experiment identifies the ATE. Basically, we’re saying that $S$ is as-good-as-random within each $C = c_i$ group, so we can treat $S$ as being like an experimentally assigned variable within groups:\n",
        "\\begin{align*}\n",
        "\\text{ATE} &= \\sum_{i=1}^k \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid C = c_i]P(C = c_i) \\\\\n",
        "&= \\sum_{i=1}^k \\left(\\mathbb{E}[Y(S = 1, U) \\mid C = c_i] - \\mathbb{E}[Y(S = 0, U) \\mid C = c_i]\\right)P(C = c_i) \\quad \\text{(Prop. of exp.)} \\\\\n",
        "&= \\sum_{i=1}^k \\left(\\mathbb{E}[Y(S = 1, U) \\mid C = c_i, S = 1] - \\mathbb{E}[Y(S = 0, U) \\mid C = c_i, S = 0]\\right)P(C = c_i) \\quad (S \\perp U \\mid C)\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "cuXoo7pDxzA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 4 (Midterm Bonus)"
      ],
      "metadata": {
        "id": "rRD2uO-d1HWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show that independence implies zero covariance. (not vice versa)"
      ],
      "metadata": {
        "id": "Q22fA4B51Hjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have shown this in lectures before.\n",
        "\n",
        "Let $X$ and $Y$ be independent random variables. By definition, the covariance of $X$ and $Y$ is given by:\n",
        "$$\n",
        "\\text{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y].\n",
        "$$\n",
        "\n",
        "Since $X$ and $Y$ are independent, the joint expectation of $XY$ can be written as the product of their marginal expectations:\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[XY] &= \\mathbb{E}[\\mathbb{E}[XY \\mid X]] \\quad \\text{(LIE)} \\\\\n",
        "&= \\mathbb{E}[X \\mathbb{E}[Y \\mid X]] \\quad \\text{(property of conditional expectation)} \\\\\n",
        "&= \\mathbb{E}\\left[X \\int_{-\\infty}^\\infty y f(y \\mid x) \\, dy \\right] \\quad \\text{(definition of conditional expectation)} \\\\\n",
        "&= \\mathbb{E}\\left[X \\int_{-\\infty}^\\infty y f(y) \\, dy \\right] \\quad \\text{(independence: \\( Y \\perp X \\))} \\\\\n",
        "&= \\mathbb{E}[X \\mathbb{E}[Y]] \\\\\n",
        "&= \\mathbb{E}[X]\\mathbb{E}[Y].\n",
        "\\end{align*}\n",
        "\n",
        "(This also showed that $\\mathbb{E}[Y|X] = \\mathbb{E}[Y]$ given independence.)\n",
        "\n",
        "Substituting this into the covariance formula:\n",
        "\\begin{align*}\n",
        "\\text{Cov}(X, Y) &= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] \\\\\n",
        "&= \\mathbb{E}[X]\\mathbb{E}[Y] - \\mathbb{E}[X]\\mathbb{E}[Y] \\\\\n",
        "&= 0.\n",
        "\\end{align*}\n",
        "\n",
        "Thus, if $X$ and $Y$ are independent random variables, their covariance is zero."
      ],
      "metadata": {
        "id": "iONWOtyeJr_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Selected Lecture Proofs"
      ],
      "metadata": {
        "id": "gO0PuAJzmbN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proof 1"
      ],
      "metadata": {
        "id": "WrWJbY78nJEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show DID estimator identifies the ATT under the parallel trends assumption."
      ],
      "metadata": {
        "id": "cXkNJAzCnLO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the DID estimator as the following,\n",
        "\n",
        "$$\n",
        "DID = \\mathbb{E}[Y_{1,1}(S = 1, U)] - \\mathbb{E}[Y_{1,0}(S = 0, U)] -\n",
        "\\Big(\\mathbb{E}[Y_{0,1}(S = 0, U)] - \\mathbb{E}[Y_{0,0}(S = 0, U)]\\Big)\n",
        "$$\n",
        "\n",
        "and the parrlel trends assumption\n",
        "\n",
        "$$\n",
        "\\mathbb{E}[Y_{1,1}(S = 0, U) - Y_{1,0}(S = 0, U)] =\n",
        "\\mathbb{E}[Y_{0,1}(S = 0, U) - Y_{0,0}(S = 0, U)]\n",
        "$$\n",
        "\n",
        "We would like to show that the DID estimator identifies ATT:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "DID &= \\mathbb{E}[Y_{1,1}(S = 1, U)] - \\mathbb{E}[Y_{1,0}(S = 0, U)] -\n",
        "(\\mathbb{E}[Y_{0,1}(S = 0, U)] - \\mathbb{E}[Y_{0,0}(S = 0, U)]) \\\\\n",
        "&= \\mathbb{E}[Y_{1,1}(S = 1, U)] - \\mathbb{E}[Y_{1,1}(S = 0, U)] +\n",
        "\\mathbb{E}[Y_{1,1}(S = 0, U)] - \\mathbb{E}[Y_{1,0}(S = 0, U)] -\n",
        "(\\mathbb{E}[Y_{0,1}(S = 0, U)] - \\mathbb{E}[Y_{0,0}(S = 0, U)]) \\\\\n",
        "& = ATT +\n",
        "\\mathbb{E}[Y_{1,1}(S = 0, U)] - \\mathbb{E}[Y_{1,0}(S = 0, U)] -\n",
        "(\\mathbb{E}[Y_{0,1}(S = 0, U)] - \\mathbb{E}[Y_{0,0}(S = 0, U)]) \\\\\n",
        "&= ATT + 0 \\quad \\text{(Parr. trends)}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "i0W7S50TnnTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proof 2"
      ],
      "metadata": {
        "id": "cQmcuEuWq2S5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show why we can use linear regression to estimate the DID parameter with $\\alpha_3$ from the following:\n",
        "\n",
        "$$\n",
        "Y = \\alpha_0 + \\alpha_1 T + \\alpha_2 G + \\alpha_3 D\n",
        "$$"
      ],
      "metadata": {
        "id": "KIC-gSSHrhzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[Y_{g,t} \\mid T, G, D] &= \\mathbb{E}[Y_{0,0}] + T(\\mathbb{E}[Y_{0,1}] - \\mathbb{E}[Y_{0,0}]) \\\\\n",
        "&\\quad + S(\\mathbb{E}[Y_{1,0}] - \\mathbb{E}[Y_{0,0}]) \\\\\n",
        "&\\quad + D(\\mathbb{E}[Y_{1,1}] - \\mathbb{E}[Y_{1,0}] - \\mathbb{E}[Y_{0,1}] + \\mathbb{E}[Y_{0,0}]) \\\\\n",
        "&= \\mathbb{E}[Y_{0,0}] + T(\\mathbb{E}[Y_{0,1}] - \\mathbb{E}[Y_{0,0}]) \\\\\n",
        "&\\quad + S(\\mathbb{E}[Y_{1,0}] - \\mathbb{E}[Y_{0,0}]) + D \\cdot DID\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "n5iRhYqxrjPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proof 3"
      ],
      "metadata": {
        "id": "HM1d7g27r9i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How did we identify the RDD estimator with the smoothness assumption?"
      ],
      "metadata": {
        "id": "S4vFJ4gysB2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\n",
        "\\mathbb{E}[Y \\mid R = c] &= \\mathbb{E}[Y(S = 1, U) \\mid R = c] \\quad \\text{(r $\\geq$ c $\\implies$ S = 1)} \\\\\n",
        "\\lim_{r \\uparrow c} \\mathbb{E}[Y \\mid R = r] &= \\lim_{r \\uparrow c} \\mathbb{E}[Y(S = 0, U) \\mid R = r] \\quad \\text{(r $<$ c $\\implies$ S = 0)} \\\\\n",
        "&= \\mathbb{E}[Y(S = 0, U) \\mid R = c] \\quad \\text{(smoothness)}.\n",
        "\\end{align*}\n",
        "\n",
        "\\begin{align*}\n",
        "\\implies \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid R = c]\n",
        "&= \\mathbb{E}[Y(S = 1, U) \\mid R = c] - \\lim_{r \\uparrow c} \\mathbb{E}[Y(S = 0, U) \\mid R = r].\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "cUZewmpCsB6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can estimate this using local linear regression below. Why does $\\alpha_1$ estimate the above effect, and what does each parameter do here?"
      ],
      "metadata": {
        "id": "SN4Boo6sc-T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "Y = \\alpha_0 + \\alpha_1 S + \\alpha_2 (R - c) + \\alpha_3 S \\cdot (R - c)\n",
        "$$"
      ],
      "metadata": {
        "id": "GyLpB6rldKk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proof 4"
      ],
      "metadata": {
        "id": "imJzJ89cr_1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show that the Wald estimator identifies LATE."
      ],
      "metadata": {
        "id": "7HEn0myesCoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Wald estimator can be written as the following:\n",
        "\n",
        "\\begin{align*}\n",
        "\\alpha_1^{IV} &= \\frac{\\text{Cov}(Z, Y)}{\\text{Cov}(Z, S)} = \\frac{\\text{Cov}(Z, Y) / \\text{Var}(Z)}{\\text{Cov}(Z, S) / \\text{Var}(Z)} = \\frac{\\mathbb{E}[Y \\mid Z = 1] - \\mathbb{E}[Y \\mid Z = 0]}{\\mathbb{E}[S \\mid Z = 1] - \\mathbb{E}[S \\mid Z = 0]}.\n",
        "\\end{align*}\n",
        "\n",
        "We expand the numerator and denominator separately.\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[Y \\mid Z = 1] - \\mathbb{E}[Y \\mid Z = 0]\n",
        "&= \\mathbb{E}[Y(S, U) \\mid Z = 1] - \\mathbb{E}[Y(S, U) \\mid Z = 0] \\\\\n",
        "&= \\mathbb{E}[Y(S(Z = 1, V), U) \\mid Z = 1] - \\mathbb{E}[Y(S(Z = 0, V), U) \\mid Z = 0] \\\\\n",
        "&= \\mathbb{E}[Y(S(Z = 1, V), U)] - \\mathbb{E}[Y(S(Z = 0, V), U)] \\quad \\text{(Instr. Exog.)} \\\\\n",
        "&= \\mathbb{E}[Y(S(Z = 1, V), U) - Y(S(Z = 0, V), U)] \\\\\n",
        "&= \\mathbb{E}[\\mathbb{E}[Y(S(1, V), U) - Y(S(0, V), U) \\mid S(1, V), S(0, V)]] \\quad \\text{(LIE)} \\\\\n",
        "&= \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid \\text{Complier}]P(\\text{Complier}) \\\\\n",
        "&\\quad + \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid \\text{Defier}]P(\\text{Defier}) \\\\\n",
        "&= \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid \\text{Complier}]P(\\text{Complier}) \\quad \\text{(Monot.)}.\n",
        "\\end{align*}\n",
        "\n",
        "Now for the denominator,\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbb{E}[S \\mid Z = 1] - \\mathbb{E}[S \\mid Z = 0]\n",
        "&= \\mathbb{E}[S(Z, V) \\mid Z = 1] - \\mathbb{E}[S(Z, V) \\mid Z = 0] \\\\\n",
        "&= \\mathbb{E}[S(Z = 1, V) \\mid Z = 1] - \\mathbb{E}[S(Z = 0, V) \\mid Z = 0] \\\\\n",
        "&= \\mathbb{E}[S(Z = 1, V)] - \\mathbb{E}[S(Z = 0, V)] \\quad \\text{(Instr. Exog.)} \\\\\n",
        "&= \\mathbb{E}[S(Z = 1, V) - S(Z = 0, V)] \\\\\n",
        "&= \\mathbb{E}[\\mathbb{E}[S(Z = 1, V) - S(Z = 0, V) \\mid S(1, V), S(0, V)]] \\quad \\text{(LIE)} \\\\\n",
        "&= \\mathbb{E}[1 - 0 \\mid \\text{Complier}]P(\\text{Complier}) + \\mathbb{E}[0 - 1 \\mid \\text{Defier}]P(\\text{Defier}) \\\\\n",
        "&= P(\\text{Complier}) \\quad \\text{(Monot.)}.\n",
        "\\end{align*}\n",
        "\n",
        "Putting it all together,\n",
        "\n",
        "\\begin{align*}\n",
        "\\alpha_1^{IV}\n",
        "&= \\frac{\\mathbb{E}[Y \\mid Z = 1] - \\mathbb{E}[Y \\mid Z = 0]}{\\mathbb{E}[S \\mid Z = 1] - \\mathbb{E}[S \\mid Z = 0]} \\\\\n",
        "&= \\frac{\\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid \\text{Complier}]P(\\text{Complier})}{P(\\text{Complier})} \\\\\n",
        "&= \\mathbb{E}[Y(S = 1, U) - Y(S = 0, U) \\mid \\text{Complier}] \\quad \\text{(Instr. Rel.)} \\\\\n",
        "&= \\text{LATE}.\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "Y4JmC0uZsCsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proof 5"
      ],
      "metadata": {
        "id": "bpNf8ueU-eoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the common alternative form of the covariance definition:\n",
        "$$\n",
        "\\text{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n",
        "$$"
      ],
      "metadata": {
        "id": "XArTwpCR-gp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align*}\n",
        "\\text{Cov}(X, Y) &= \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] \\\\\n",
        "&= \\mathbb{E}[XY - X\\mathbb{E}[Y] - Y\\mathbb{E}[X] + \\mathbb{E}[X]\\mathbb{E}[Y]] \\\\\n",
        "&= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] - \\mathbb{E}[Y]\\mathbb{E}[X] + \\mathbb{E}[X]\\mathbb{E}[Y] \\\\\n",
        "&= \\mathbb{E}[XY] - 2\\mathbb{E}[X]\\mathbb{E}[Y] + \\mathbb{E}[X]\\mathbb{E}[Y] \\\\\n",
        "&= \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n",
        "\\end{align*}"
      ],
      "metadata": {
        "id": "vWADg2zv-jdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Good luck with your finals!"
      ],
      "metadata": {
        "id": "mH6F1TsSLiWe"
      }
    }
  ]
}