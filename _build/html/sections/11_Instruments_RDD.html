
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>11. Instrumental Variables(Continued) &#8212; Causal Inference for Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"TeX": {"extensions": ["AMSmath.js", "AMSsymbols.js"], "equationNumbers": {"autoNumber": "none"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'sections/11_Instruments_RDD';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12. Instrumental Variables (Continued) and Intro to Regression Discontinuity (RDD)" href="12_RDD.html" />
    <link rel="prev" title="10. Instrumental Variables" href="10_Instruments.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Causal Inference for Data Science - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="Causal Inference for Data Science - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to Causal Inference
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1_Introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_Probability_1-2.html">2. Probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_Probability_Statistics.html">3. Probability, All Causes Model and Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="4_Statistics_and_Experiments.html">4. Hypothesis testing and Introduction to Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="5_Experiments.html">5. Experiments (Cont.)</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_Regression_1-2.html">6. Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="7_Natural_Experiments.html">7. Natural Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="8_ML_and_Causality.html">8. The Interplay between Machine Learning and Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="9_Matching.html">9. Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_Instruments.html">10. Instrumental Variables</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">11. Instrumental Variables(Continued)</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_RDD.html">12. Instrumental Variables (Continued) and Intro to Regression Discontinuity (RDD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_Difference_in_Differences.html">13. Difference in Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_Review.html">14. Final Review</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fsections/11_Instruments_RDD.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/sections/11_Instruments_RDD.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Instrumental Variables(Continued)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap-from-last-class">11.1. Recap From Last Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals-for-today">11.2. Goals For Today</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">11.3. 2. Instrumental Variables (Continued)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#revisit-the-effect-of-watching-sesame-street-on-later-academic-achievement">11.3.1. Revisit - The effect of watching sesame street on later academic achievement.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data">11.3.2. Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-form">11.3.3. “Reduced Form”</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#remember-non-compliance-and-itt">11.3.3.1. <strong>Remember non-compliance and ITT?</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weak-instrument">11.3.4. Weak Instrument</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">11.3.5. Estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#via-the-explicit-two-stage-least-squares-2sls-estimation">11.3.5.1. Via the (explicit) Two-Stage Least Squares (2SLS) Estimation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#via-the-iv2sls-function-from-linearmodels">11.3.5.2. Via the IV2SLS Function from linearmodels</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instrument-with-control">11.3.6. Instrument with Control</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#colider-bias">11.4. 3. Colider Bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-regression-discontinuity">11.5. 4. Introduction to Regression Discontinuity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#major-assumption">11.5.1. Major Assumption</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">11.5.2. Estimation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#path-forward">11.6. Path Forward</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div align="center">
<p><a class="reference external" href="https://colab.research.google.com/github/dapivei/causal-infere/blob/main/sections/11_Instruments_RDD.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
</div><section class="tex2jax_ignore mathjax_ignore" id="instrumental-variables-continued">
<h1><span class="section-number">11. </span>Instrumental Variables(Continued)<a class="headerlink" href="#instrumental-variables-continued" title="Link to this heading">#</a></h1>
<section id="recap-from-last-class">
<h2><span class="section-number">11.1. </span>Recap From Last Class<a class="headerlink" href="#recap-from-last-class" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Instrumental Variables</p></li>
</ul>
</section>
<section id="goals-for-today">
<h2><span class="section-number">11.2. </span>Goals For Today<a class="headerlink" href="#goals-for-today" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Direct Effect and Connection to ITT</p></li>
<li><p>Weak Instruments</p></li>
<li><p>Instruments with Control</p></li>
<li><p>Collider Bias</p></li>
<li><p>Primer on Regression Discontinuity Design</p></li>
</ol>
</section>
<section id="id1">
<h2><span class="section-number">11.3. </span>2. Instrumental Variables (Continued)<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Often, we cannot establish the following conditions to identify the causal parameter as (ubobserved) confounding can <strong>bias</strong> our estimates.</p>
<div class="math notranslate nohighlight">
\[S \not\!\perp\!\!\!\perp U, \ \ S \not\!\perp\!\!\!\perp U \ | \ C\]</div>
<p>Instrumental variables is a specific setup to help identification even in the presence of <em>unobserved confounding</em> (when control/matching would not be able to identify).</p>
<img src="https://raw.githubusercontent.com/dapivei/causal-infere/main/images/instrument.png" width="500"/>
<p>For <span class="math notranslate nohighlight">\(Z\)</span> to be a valid instrument, it must satisfy three important assumptions:</p>
<p>1.<strong>Exogeneity</strong>   2.<strong>Relevance</strong>   3.<strong>Monotonicity</strong></p>
<p>Under our LATE assumptions, the Wald estimator identifies the LATE:</p>
<div class="math notranslate nohighlight">
\[\alpha_{IV} = \frac{\text{Cov}(Z,Y)}{\text{Cov}(Z,S)} = \frac{\mathbb{E}[Y|Z =1]-\mathbb{E}[Y|Z =0]}{\mathbb{E}[S|Z =1]-\mathbb{E}[S|Z =0]}
=\mathbb{E}[Y(S =1,U)−Y(S =0,U)|Complier]= LATE\]</div>
<blockquote>
<div><p>Thus, <strong>LATE</strong> is the <strong>difference in outcomes</strong> between those who received the treatment and those who did not, <strong>for the compliers</strong>.</p>
</div></blockquote>
<section id="revisit-the-effect-of-watching-sesame-street-on-later-academic-achievement">
<h3><span class="section-number">11.3.1. </span>Revisit - The effect of watching sesame street on later academic achievement.<a class="headerlink" href="#revisit-the-effect-of-watching-sesame-street-on-later-academic-achievement" title="Link to this heading">#</a></h3>
<blockquote>
<div><p>Does watching Sesame Street (<span class="math notranslate nohighlight">\(S\)</span>) have a positive impact on later academic achievement (<span class="math notranslate nohighlight">\(Y\)</span>)?</p>
</div></blockquote>
<p>The dataset includes information on 240 children who were randomly assigned to two groups.</p>
<p>The treatment of interest here is <strong>watching</strong> Sesame Street.</p>
<p><em><strong>Model Setup</strong></em></p>
<p>\begin{aligned}
S &amp; =\left{\begin{array}{l}
1 \text { if watched Sesame }  \
0 \text { did not watched Sesame}
\end{array}\right. \
Z &amp; =\left{\begin{array}{l}
1 \text { if encouraged  }  \
0 \text { not encouraged}
\end{array}\right. \
S(Z, V) &amp; =\text {If watched Sesame} \
V &amp; =\text { other determinants of } S \
Y(S, U) &amp; =\text {Score on a literacy test} \
U &amp; =\text { other determinants of } Y,
\end{aligned}</p>
<p>where <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(V\)</span> represents correspondingly other determinants of <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(S\)</span> (e.g., socio-economic status).</p>
<p>The instrument <span class="math notranslate nohighlight">\(Z\)</span> allows us to answer the following question:</p>
<blockquote>
<div><p>How does watching Sesame Street <span class="math notranslate nohighlight">\(S\)</span> impact academic achievement <span class="math notranslate nohighlight">\(Y\)</span> for children whose likelihood of watching the program is influenced by the encouragement <span class="math notranslate nohighlight">\(Z\)</span>?</p>
</div></blockquote>
</section>
<section id="data">
<h3><span class="section-number">11.3.2. </span>Data<a class="headerlink" href="#data" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">encour</span></code></strong>: Indicator variable for whether the child was encouraged to watch Sesame Stree. Instrument <span class="math notranslate nohighlight">\(Z\)</span>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">watched</span></code></strong>: Indicator variable for whether the child actually watched Sesame Street. Treatment <span class="math notranslate nohighlight">\(S\)</span>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">letters</span></code></strong>: Score on a literacy test. Outcome <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">age</span></code></strong>: Age of the child (in months), included as a control variable.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">female</span></code></strong>: Indicator variable for gender (female), included as a control variable.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Other</span> <span class="pre">variables</span></code></strong>: Various additional factors.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">LinearSegmentedColormap</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>


<span class="n">sesame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/sesame.csv&quot;</span><span class="p">)</span>
<span class="n">sesame</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rownames</th>
      <th>id</th>
      <th>site</th>
      <th>sex</th>
      <th>age</th>
      <th>viewcat</th>
      <th>setting</th>
      <th>viewenc</th>
      <th>prebody</th>
      <th>prelet</th>
      <th>...</th>
      <th>encour</th>
      <th>_Isite_2</th>
      <th>_Isite_3</th>
      <th>_Isite_4</th>
      <th>_Isite_5</th>
      <th>regular</th>
      <th>watched</th>
      <th>encouraged</th>
      <th>y</th>
      <th>pretest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>66</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>16</td>
      <td>23</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>30</td>
      <td>23</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>67</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>30</td>
      <td>26</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>37</td>
      <td>26</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>56</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>22</td>
      <td>14</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>46</td>
      <td>14</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>49</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>23</td>
      <td>11</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>14</td>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>69</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>32</td>
      <td>47</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>63</td>
      <td>47</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 32 columns</p>
</div></div></div>
</div>
</section>
<section id="reduced-form">
<h3><span class="section-number">11.3.3. </span>“Reduced Form”<a class="headerlink" href="#reduced-form" title="Link to this heading">#</a></h3>
<p>We can estimate the direct effect (ATE) of <span class="math notranslate nohighlight">\(Z\)</span> on <span class="math notranslate nohighlight">\(Y\)</span>: how does the act of encouraging influence the later score performance?</p>
<p>This would be a valid causal estimate as the exogeneity assumption informs us of the independence assumption: <span class="math notranslate nohighlight">\(Z \perp U\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;y ~ encour&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span> <span class="c1"># you can also try robust sd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.011</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.007</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.593</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 22 Dec 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.109</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>20:28:05</td>     <th>  Log-Likelihood:    </th> <td> -961.16</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   240</td>      <th>  AIC:               </th> <td>   1926.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   238</td>      <th>  BIC:               </th> <td>   1933.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   24.9205</td> <td>    1.421</td> <td>   17.536</td> <td> 0.000</td> <td>   22.121</td> <td>   27.720</td>
</tr>
<tr>
  <th>encour</th>    <td>    2.8756</td> <td>    1.786</td> <td>    1.610</td> <td> 0.109</td> <td>   -0.642</td> <td>    6.393</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>43.130</td> <th>  Durbin-Watson:     </th> <td>   1.269</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  20.314</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.535</td> <th>  Prob(JB):          </th> <td>3.88e-05</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.059</td> <th>  Cond. No.          </th> <td>    3.06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>The act of encouraging kids to watch Sesame Street has a nearly 3-point increase in their test scores! (though the p-value is not particularly small)</p>
<section id="remember-non-compliance-and-itt">
<h4><span class="section-number">11.3.3.1. </span><strong>Remember non-compliance and ITT?</strong><a class="headerlink" href="#remember-non-compliance-and-itt" title="Link to this heading">#</a></h4>
<p>We can re-interpret this setup as the old ATE estimation problem. The treatment of interest, in this case, watching Sesame, cannot be enforced. We can randomize who are asked to watch Sesame Street, but there will be the non-compliance issue that prevents us from deriving ATE (given the always-takers and never-takers).</p>
<p>We have learned that we can change the causal question when there is non-compliance from ATE to Intent-to-Treat (ITT) effect.</p>
<p>The ITT estimates the causal effect of <em>treatment assignment</em> on the outcome of interest. Here, the ITT estimates the causal effect of being encouraged to watch Sesame Street on a child’s score on the literacy test.</p>
<p>Hence, the <em>treatment assignment</em> can also be framed as an instrumental variable. The direct effect we obtained above can also be thought of as being a ITT estimate.</p>
</section>
</section>
<section id="weak-instrument">
<h3><span class="section-number">11.3.4. </span>Weak Instrument<a class="headerlink" href="#weak-instrument" title="Link to this heading">#</a></h3>
<p>We have briefly covered testing assumptions from last week’s lab.</p>
<p>For <strong>exogeneity</strong>, we can check for the distribution balance for some control variables across different values of instrument <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p>For <strong>relevance</strong>, in general, we can check the relationship between <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>. One approach is to look at the first-stage regression.</p>
<p>For <strong>monotonicity</strong>, this assumption is technically untestable. For example, we want to understand whether there are defilers or not in our data. However, we do not observe the counterfactual outcome for each individual (fundamental problem of causal inference). We can still reason about monotonicity based on previous evidence and assess whether this will likely be true for specific problem setup.</p>
<p>In particular, the <em><strong>weak instrument</strong></em> problem relates to the <strong>relevance</strong> assumption.</p>
<p>For the instrument to be relevant, it must be correlated with <span class="math notranslate nohighlight">\(S\)</span> – watching Sesame Street. Meaning that encouragement to watch Sesame Street has to actually make some kids more likely to watch it.</p>
<div class="math notranslate nohighlight">
\[P(\text{Complier})&gt;0 \]</div>
<p>We only require the proportion of compliers to be greater than <span class="math notranslate nohighlight">\(0\)</span>. This will still be true when the number is small or close to <span class="math notranslate nohighlight">\(0\)</span>, which gives us a weak instrument. It will blow up our estimator as the denominator of Cov<span class="math notranslate nohighlight">\((S, Z)\)</span> is small.</p>
<p>Similarly, we can test this with first-stage linear regression of the following form:
$<span class="math notranslate nohighlight">\(
S = \beta_0 + \beta_1 Z
\)</span>$
Once we fit the model, we can check for the F-statistic or t-statistic as we only have one independent variable in this regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;watched ~ encour&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>watched</td>     <th>  R-squared:         </th> <td>   0.175</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.171</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   50.46</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 22 Dec 2024</td> <th>  Prob (F-statistic):</th> <td>1.40e-11</td>
</tr>
<tr>
  <th>Time:</th>                 <td>20:28:05</td>     <th>  Log-Likelihood:    </th> <td> -107.88</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   240</td>      <th>  AIC:               </th> <td>   219.8</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   238</td>      <th>  BIC:               </th> <td>   226.7</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    0.5455</td> <td>    0.041</td> <td>   13.434</td> <td> 0.000</td> <td>    0.465</td> <td>    0.625</td>
</tr>
<tr>
  <th>encour</th>    <td>    0.3624</td> <td>    0.051</td> <td>    7.104</td> <td> 0.000</td> <td>    0.262</td> <td>    0.463</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>28.214</td> <th>  Durbin-Watson:     </th> <td>   1.734</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  35.601</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.943</td> <th>  Prob(JB):          </th> <td>1.86e-08</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.042</td> <th>  Cond. No.          </th> <td>    3.06</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>The coefficient is 0.3624, meaning that being encouraged to watch Sesame Street increases the likelihood of watching the program by approximately 36.24% compared to those who were not encouraged.</p>
<p>The F-statistic is 50.46 which is more than the threshold 10 presented in the lecture.</p>
<p>Both p-values for the F/t-statistic are extremely small. Hence, we do not have a weak instrument problem here.</p>
</section>
<section id="estimation">
<h3><span class="section-number">11.3.5. </span>Estimation<a class="headerlink" href="#estimation" title="Link to this heading">#</a></h3>
<p>From last week, we saw that we can estimate using the covariance functions as well as running two-stage squares.</p>
<p>A more direct method is to call <code class="docutils literal notranslate"><span class="pre">IV2SLS</span></code> from <code class="docutils literal notranslate"><span class="pre">linearmodels</span></code> package.</p>
<ul class="simple">
<li><p>We would need to install it first in Colab.</p></li>
</ul>
<section id="via-the-explicit-two-stage-least-squares-2sls-estimation">
<h4><span class="section-number">11.3.5.1. </span>Via the (explicit) Two-Stage Least Squares (2SLS) Estimation<a class="headerlink" href="#via-the-explicit-two-stage-least-squares-2sls-estimation" title="Link to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>First stage</strong>: Regress whether children watched Sesame Street <span class="math notranslate nohighlight">\(S\)</span> on the instrument <span class="math notranslate nohighlight">\(Z\)</span> (whether they were encouraged to watch).</p></li>
<li><p><strong>Second stage</strong>: Regress the outcome (e.g., academic performance <span class="math notranslate nohighlight">\(Y\)</span>) on the predicted values of <span class="math notranslate nohighlight">\(S\)</span> from the first stage.</p></li>
</ol>
<p>This method isolates the causal effect of watching Sesame Street on the outcome for <strong>compliers</strong> (those who watched due to encouragement).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">first_stage</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;watched ~ encour&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">sesame</span><span class="p">[</span><span class="s1">&#39;predicted_watched&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">first_stage</span><span class="o">.</span><span class="n">fittedvalues</span>
<span class="n">second_stage</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;y ~ predicted_watched&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">late_2sls_manual</span> <span class="o">=</span> <span class="n">second_stage</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;predicted_watched&#39;</span><span class="p">]</span>
<span class="n">late_2sls_manual</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(7.933993399339921)
</pre></div>
</div>
</div>
</div>
<p>For those children who are encouraged to watch Sesame Street and actually end up watching it, their academic achievement (e.g., literacy scores) increases by 7.94 units on average.</p>
</section>
<section id="via-the-iv2sls-function-from-linearmodels">
<h4><span class="section-number">11.3.5.2. </span>Via the IV2SLS Function from linearmodels<a class="headerlink" href="#via-the-iv2sls-function-from-linearmodels" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>linearmodels
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: linearmodels in /ext3/miniforge3/lib/python3.12/site-packages (6.1)
Requirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (2.2.1)
Requirement already satisfied: pandas&gt;=1.4.0 in /home/dp3766/.local/lib/python3.12/site-packages (from linearmodels) (2.2.3)
Requirement already satisfied: scipy&gt;=1.8.0 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (1.14.1)
Requirement already satisfied: statsmodels&gt;=0.13.0 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (0.14.4)
Requirement already satisfied: mypy-extensions&gt;=0.4 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (1.0.0)
Requirement already satisfied: Cython&gt;=3.0.10 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (3.0.11)
Requirement already satisfied: pyhdfe&gt;=0.1 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (0.2.0)
Requirement already satisfied: formulaic&gt;=1.0.0 in /ext3/miniforge3/lib/python3.12/site-packages (from linearmodels) (1.1.1)
Requirement already satisfied: setuptools-scm&lt;9.0.0,&gt;=8.0.0 in /ext3/miniforge3/lib/python3.12/site-packages (from setuptools-scm[toml]&lt;9.0.0,&gt;=8.0.0-&gt;linearmodels) (8.1.0)
Requirement already satisfied: interface-meta&gt;=1.2.0 in /ext3/miniforge3/lib/python3.12/site-packages (from formulaic&gt;=1.0.0-&gt;linearmodels) (1.3.0)
Requirement already satisfied: typing-extensions&gt;=4.2.0 in /ext3/miniforge3/lib/python3.12/site-packages (from formulaic&gt;=1.0.0-&gt;linearmodels) (4.12.2)
Requirement already satisfied: wrapt&gt;=1.0 in /home/dp3766/.local/lib/python3.12/site-packages (from formulaic&gt;=1.0.0-&gt;linearmodels) (1.16.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: python-dateutil&gt;=2.8.2 in /ext3/miniforge3/lib/python3.12/site-packages (from pandas&gt;=1.4.0-&gt;linearmodels) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /home/dp3766/.local/lib/python3.12/site-packages (from pandas&gt;=1.4.0-&gt;linearmodels) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /home/dp3766/.local/lib/python3.12/site-packages (from pandas&gt;=1.4.0-&gt;linearmodels) (2024.2)
Requirement already satisfied: packaging&gt;=20 in /ext3/miniforge3/lib/python3.12/site-packages (from setuptools-scm&lt;9.0.0,&gt;=8.0.0-&gt;setuptools-scm[toml]&lt;9.0.0,&gt;=8.0.0-&gt;linearmodels) (24.2)
Requirement already satisfied: setuptools in /ext3/miniforge3/lib/python3.12/site-packages (from setuptools-scm&lt;9.0.0,&gt;=8.0.0-&gt;setuptools-scm[toml]&lt;9.0.0,&gt;=8.0.0-&gt;linearmodels) (75.6.0)
Requirement already satisfied: patsy&gt;=0.5.6 in /ext3/miniforge3/lib/python3.12/site-packages (from statsmodels&gt;=0.13.0-&gt;linearmodels) (1.0.1)
Requirement already satisfied: six&gt;=1.5 in /ext3/miniforge3/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=1.4.0-&gt;linearmodels) (1.17.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">linearmodels</span> <span class="k">as</span> <span class="nn">lm</span>

<span class="n">lm</span><span class="o">.</span><span class="n">IV2SLS</span><span class="o">.</span><span class="n">from_formula</span><span class="p">(</span><span class="s1">&#39;y ~ 1 + [watched ~ encour]&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>0.1355</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.1318</td> 
</tr>
<tr>
  <th>No. Observations:</th>        <td>240</td>       <th>  F-statistic:       </th> <td>2.9570</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Sun, Dec 22 2024</td> <th>  P-value (F-stat)   </th> <td>0.0855</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>20:28:06</td>     <th>  Distribution:      </th> <td>chi2(1)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th> <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>  <td>20.593</td>    <td>3.6811</td>   <td>5.5942</td> <td>0.0000</td>   <td>13.378</td>   <td>27.808</td> 
</tr>
<tr>
  <th>watched</th>    <td>7.9340</td>    <td>4.6138</td>   <td>1.7196</td> <td>0.0855</td>   <td>-1.1090</td>  <td>16.977</td> 
</tr>
</table><br/><br/>Endogenous: watched<br/>Instruments: encour<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False</div></div>
</div>
</section>
</section>
<section id="instrument-with-control">
<h3><span class="section-number">11.3.6. </span>Instrument with Control<a class="headerlink" href="#instrument-with-control" title="Link to this heading">#</a></h3>
<p>If we have extra observed characteristics, we can control them as part of the IV procedure.</p>
<p>This could potentially make the exogeneity argument stronger via conditional independence.</p>
<div class="math notranslate nohighlight">
\[
Z \perp U | C
\]</div>
<p>However, this will impact the parameter estimate as we saw in regression with control. The weights for each controlled subgroup will change to the covariance of <span class="math notranslate nohighlight">\(Z\)</span> and <span class="math notranslate nohighlight">\(S\)</span> in that group.</p>
<div class="math notranslate nohighlight">
\[
\alpha_1^{\text{IV, Cont.}} = E \left[ \frac{\text{Cov}(Z, S | C = c)}{\text{Cov}(Z, S)} \text{LATE}(C = c) \right]
\]</div>
<p>Let’s try controlling for two variables <code class="docutils literal notranslate"><span class="pre">age</span></code> and <code class="docutils literal notranslate"><span class="pre">sex</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">first_stage</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;watched ~ encour + age + sex&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">sesame</span><span class="p">[</span><span class="s1">&#39;predicted_watched&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">first_stage</span><span class="o">.</span><span class="n">fittedvalues</span>
<span class="n">second_stage</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;y ~ predicted_watched + age + sex&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">late_2sls_manual</span> <span class="o">=</span> <span class="n">second_stage</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;predicted_watched&#39;</span><span class="p">]</span>
<span class="n">late_2sls_manual</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(8.482026098072684)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># direct method</span>
<span class="n">lm</span><span class="o">.</span><span class="n">IV2SLS</span><span class="o">.</span><span class="n">from_formula</span><span class="p">(</span><span class="s1">&#39;y ~ 1 + age + sex + [watched ~ encour]&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sesame</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>IV-2SLS Estimation Summary</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>0.2077</td> 
</tr>
<tr>
  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>0.1976</td> 
</tr>
<tr>
  <th>No. Observations:</th>        <td>240</td>       <th>  F-statistic:       </th> <td>25.201</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Sun, Dec 22 2024</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>20:28:07</td>     <th>  Distribution:      </th> <td>chi2(3)</td>
</tr>
<tr>
  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>    <td></td>    
</tr>
<tr>
  <th></th>                          <td></td>         <th>                     </th>    <td></td>    
</tr>
</table>
<table class="simpletable">
<caption>Parameter Estimates</caption>
<tr>
      <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>
</tr>
<tr>
  <th>Intercept</th>  <td>-10.571</td>   <td>7.6520</td>   <td>-1.3814</td> <td>0.1671</td>   <td>-25.568</td>  <td>4.4270</td> 
</tr>
<tr>
  <th>age</th>        <td>0.5505</td>    <td>0.1190</td>   <td>4.6241</td>  <td>0.0000</td>   <td>0.3172</td>   <td>0.7838</td> 
</tr>
<tr>
  <th>sex</th>        <td>1.5620</td>    <td>1.5530</td>   <td>1.0058</td>  <td>0.3145</td>   <td>-1.4818</td>  <td>4.6058</td> 
</tr>
<tr>
  <th>watched</th>    <td>8.4820</td>    <td>4.3245</td>   <td>1.9614</td>  <td>0.0498</td>   <td>0.0062</td>   <td>16.958</td> 
</tr>
</table><br/><br/>Endogenous: watched<br/>Instruments: encour<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False</div></div>
</div>
<p>Our estimate is now 8.48 points. Nevertheless, in this <strong>experiment</strong>, we know beforehand that the instrument <span class="math notranslate nohighlight">\(Z\)</span> was randomly assigned.</p>
</section>
</section>
<section id="colider-bias">
<h2><span class="section-number">11.4. </span>3. Colider Bias<a class="headerlink" href="#colider-bias" title="Link to this heading">#</a></h2>
<p>Besides complicated interpretations, controlling for more variables can also get us in trouble due to colider bias.</p>
<p>In previous labs, we covered a brief overview of different types of conditional independence structures.</p>
<p><img alt="Indep" src="https://catalogofbias.org/wp-content/uploads/sites/2/2019/03/Collider-bias_fig-1-e1551439537528.png" /></p>
<p><strong>Collider bias</strong> occurs when two variables independently influence a third variable (called a collider), and we condition on or control for this collider (or its descedents).</p>
<p>This conditioning can induce a spurious association between the two independent variables, leading to incorrect conclusions about their relationship. What are some real-life examples?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># For reproducibility</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># Sample size</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">S</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Y</span> <span class="o">+</span> <span class="n">noise</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;S&#39;</span><span class="p">:</span> <span class="n">S</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">C</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>For simplicity, we will not introduce any dependence between <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> to demonstrate how conditioning on <span class="math notranslate nohighlight">\(C\)</span> creates dependence from 0.</p>
<p>In practice, <span class="math notranslate nohighlight">\(S\)</span> does influence <span class="math notranslate nohighlight">\(Y\)</span> directly, which is the direct causal effect of interest. Conditioning on <span class="math notranslate nohighlight">\(C\)</span> will bias the effect with extra dependence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_full</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Correlation between S and Y in the full dataset: </span><span class="si">{</span><span class="n">corr_full</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation between S and Y in the full dataset: -0.0086
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="mi">90</span><span class="p">)</span>
<span class="n">data_conditioned</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">]</span>

<span class="n">corr_conditioned</span> <span class="o">=</span> <span class="n">data_conditioned</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">data_conditioned</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Correlation between S and Y after conditioning on C: </span><span class="si">{</span><span class="n">corr_conditioned</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation between S and Y after conditioning on C: -0.6000
</pre></div>
</div>
</div>
</div>
<p>This negative correlation indicates that X and Y are now dependent after conditioning on Z, demonstrating collider bias.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scatter Plot of S vs Y (Full Dataset)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c38a950938f46c60178d42b6c4a6242c236dbf557390c3a3f45a5c6d2da44827.png" src="../_images/c38a950938f46c60178d42b6c4a6242c236dbf557390c3a3f45a5c6d2da44827.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_conditioned</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scatter Plot of S vs Y (Conditioned on Z)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/635902068faca74a05b7f6443d31677aee6ddea68f776b29d5917a5fcc5d9afb.png" src="../_images/635902068faca74a05b7f6443d31677aee6ddea68f776b29d5917a5fcc5d9afb.png" />
</div>
</div>
<p>We should be careful about which variables to control and reason about them based on the problem context to avoid additional bias.</p>
</section>
<section id="introduction-to-regression-discontinuity">
<h2><span class="section-number">11.5. </span>4. Introduction to Regression Discontinuity<a class="headerlink" href="#introduction-to-regression-discontinuity" title="Link to this heading">#</a></h2>
<p>Most things in nature are continuous. If we see spikes or jumps, they are very likely to be <strong>artificial</strong>.</p>
<p>How can we leverage this phenomenon to derive valid causal estimates?</p>
<p>We will need to rely on some continuous variables <span class="math notranslate nohighlight">\(R\)</span> that defines the treatment/control group via thresholds <span class="math notranslate nohighlight">\(c\)</span> of <span class="math notranslate nohighlight">\(R\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
S =
\begin{cases}
1 &amp; \text{if } R \geq c \\
0 &amp; \text{if } R &lt; c
\end{cases}
\end{split}\]</div>
<p>The core intuition for the validity of this method is that people near/around this cutoff <span class="math notranslate nohighlight">\(c\)</span> should be randomly placed into treatment vs. control.</p>
<p>For example, there is no systematic reason for why someone got 91 on a test vs. someone got 89 except for some random chance.</p>
<p>Therefore, similar to LATE, the causal estimate from RDD can only be applied to the subgroup around cutoffs instead of the general population.</p>
<img src="https://raw.githubusercontent.com/dapivei/causal-infere/a5e0159feda3746ba84a5e9bfec4e2a890685eb4/images/rdd.png" width="600"><section id="major-assumption">
<h3><span class="section-number">11.5.1. </span>Major Assumption<a class="headerlink" href="#major-assumption" title="Link to this heading">#</a></h3>
<p>To estimate the differences, we require the expected potential outcomes is a <em><strong>continuous</strong></em> function of the running variable at the cutoff <span class="math notranslate nohighlight">\(c\)</span> (smoothness assumption).</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \mathbb{E}[Y | R = c] &amp;= \mathbb{E}[Y(S = 1, U) | R = c] \quad &amp; (r \geq c \Rightarrow S = 1) \\
    \lim_{r \uparrow c} \mathbb{E}[Y | R = r] &amp;= \lim_{r \uparrow c} \mathbb{E}[Y(S = 0, U) | R = r] \quad &amp; (r &lt; c \Rightarrow S = 0) \\
    &amp;= \mathbb{E}[Y(S = 0, U) | R = c] \quad &amp; (\text{smoothness})
\end{align*}
\end{split}\]</div>
<p>Practically, we need to select a bandwidth parameter <span class="math notranslate nohighlight">\(b\)</span> to allow more samples around the cutoff point. This introduces a bias/variance tradeoff based on the magnitude of the bandwidth.</p>
<p>We can also simply check for multiple options of <span class="math notranslate nohighlight">\(b\)</span> for robustness.</p>
</section>
<section id="id2">
<h3><span class="section-number">11.5.2. </span>Estimation<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>We can estimate the difference in the above potential outcomes by selecting a bandwidth and using local linear regression:</p>
<div class="math notranslate nohighlight">
\[
Y = \alpha_0 + \alpha_1 S + \alpha_2 (R - c) + \alpha_3 S \cdot (R - c) + \epsilon
\]</div>
<p>Under the smoothness assumption and “small enough” bandwidth, we can identify the causal parameter through <span class="math notranslate nohighlight">\(\alpha_1\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\alpha_1 = \mathbb{E}[Y(S = 1, U) -  Y(S = 0, U)| R = c]
\]</div>
<p>The centering allows the intercept terms to become the corresponding differences at <span class="math notranslate nohighlight">\(R=c\)</span>, and the interaction term allows different slopes for the two potential outcome functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">running_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">treatment</span> <span class="o">=</span> <span class="p">(</span><span class="n">running_var</span> <span class="o">&gt;=</span> <span class="mi">90</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">outcome</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">treatment</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">running_var</span> <span class="o">-</span> <span class="mi">90</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;running_var&#39;</span><span class="p">:</span> <span class="n">running_var</span><span class="p">,</span>
    <span class="s1">&#39;treatment&#39;</span><span class="p">:</span> <span class="n">treatment</span><span class="p">,</span>
    <span class="s1">&#39;outcome&#39;</span><span class="p">:</span> <span class="n">outcome</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>We can plot our data and check for the jump around cutoff.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;outcome&#39;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;treatment&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bwr&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cutoff&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Running Variable&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Outcome&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Outcome by Running Variable with Cutoff&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/132cda51c8fa4997a790283d5a0c15dae6ccbec3c319de27a49c0ecf09385ec4.png" src="../_images/132cda51c8fa4997a790283d5a0c15dae6ccbec3c319de27a49c0ecf09385ec4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_local_regression</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bandwidth</span><span class="p">):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">90</span> <span class="o">-</span> <span class="n">bandwidth</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">90</span> <span class="o">+</span> <span class="n">bandwidth</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;running_var_centered&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">90</span>
    <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;treatment:running_var_centered&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;treatment&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;running_var_centered&#39;</span><span class="p">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;outcome ~ treatment + running_var_centered + treatment:running_var_centered&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">subset</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">results</span>

<span class="c1"># example with bandwidth of 2</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">run_local_regression</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bandwidth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                outcome   R-squared:                       0.724
Model:                            OLS   Adj. R-squared:                  0.695
Method:                 Least Squares   F-statistic:                     24.49
Date:                Sun, 22 Dec 2024   Prob (F-statistic):           5.54e-08
Time:                        20:28:07   Log-Likelihood:                -63.622
No. Observations:                  32   AIC:                             135.2
Df Residuals:                      28   BIC:                             141.1
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==================================================================================================
                                     coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                         19.1176      0.948     20.163      0.000      17.175      21.060
treatment                          6.0641      1.182      5.131      0.000       3.643       8.485
running_var_centered              -0.5285      0.859     -0.615      0.544      -2.289       1.232
treatment:running_var_centered     0.8905      1.099      0.810      0.425      -1.361       3.142
==============================================================================
Omnibus:                        5.254   Durbin-Watson:                   1.426
Prob(Omnibus):                  0.072   Jarque-Bera (JB):                3.641
Skew:                           0.731   Prob(JB):                        0.162
Kurtosis:                       3.770   Cond. No.                         8.01
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<p>We can check for the parameter estimates under different bandwidths.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">bw</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results for Bandwidth = </span><span class="si">{</span><span class="n">bw</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">run_local_regression</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bw</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Results for Bandwidth = 1
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                outcome   R-squared:                       0.681
Model:                            OLS   Adj. R-squared:                  0.621
Method:                 Least Squares   F-statistic:                     11.37
Date:                Sun, 22 Dec 2024   Prob (F-statistic):           0.000305
Time:                        20:28:07   Log-Likelihood:                -41.162
No. Observations:                  20   AIC:                             90.32
Df Residuals:                      16   BIC:                             94.31
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==================================================================================================
                                     coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                         19.1586      1.266     15.132      0.000      16.475      21.843
treatment                          6.9221      1.717      4.032      0.001       3.282      10.562
running_var_centered              -0.5390      2.888     -0.187      0.854      -6.662       5.584
treatment:running_var_centered    -1.0926      3.603     -0.303      0.766      -8.731       6.546
==============================================================================
Omnibus:                        4.152   Durbin-Watson:                   2.200
Prob(Omnibus):                  0.125   Jarque-Bera (JB):                2.348
Skew:                           0.805   Prob(JB):                        0.309
Kurtosis:                       3.476   Cond. No.                         12.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Results for Bandwidth = 5
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                outcome   R-squared:                       0.829
Model:                            OLS   Adj. R-squared:                  0.823
Method:                 Least Squares   F-statistic:                     144.0
Date:                Sun, 22 Dec 2024   Prob (F-statistic):           4.94e-34
Time:                        20:28:07   Log-Likelihood:                -191.73
No. Observations:                  93   AIC:                             391.5
Df Residuals:                      89   BIC:                             401.6
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==================================================================================================
                                     coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                         20.2777      0.666     30.464      0.000      18.955      21.600
treatment                          4.8941      0.847      5.778      0.000       3.211       6.577
running_var_centered               0.7216      0.207      3.480      0.001       0.310       1.134
treatment:running_var_centered    -0.1941      0.283     -0.684      0.495      -0.757       0.369
==============================================================================
Omnibus:                        0.554   Durbin-Watson:                   2.102
Prob(Omnibus):                  0.758   Jarque-Bera (JB):                0.172
Skew:                           0.019   Prob(JB):                        0.918
Kurtosis:                       3.207   Cond. No.                         17.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Results for Bandwidth = 10
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                outcome   R-squared:                       0.884
Model:                            OLS   Adj. R-squared:                  0.882
Method:                 Least Squares   F-statistic:                     496.3
Date:                Sun, 22 Dec 2024   Prob (F-statistic):           2.87e-91
Time:                        20:28:07   Log-Likelihood:                -413.89
No. Observations:                 200   AIC:                             835.8
Df Residuals:                     196   BIC:                             849.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==================================================================================================
                                     coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
Intercept                         19.3942      0.432     44.883      0.000      18.542      20.246
treatment                          5.9178      0.578     10.244      0.000       4.779       7.057
running_var_centered               0.3729      0.072      5.189      0.000       0.231       0.515
treatment:running_var_centered     0.1030      0.098      1.052      0.294      -0.090       0.296
==============================================================================
Omnibus:                        6.502   Durbin-Watson:                   2.124
Prob(Omnibus):                  0.039   Jarque-Bera (JB):                7.856
Skew:                           0.244   Prob(JB):                       0.0197
Kurtosis:                       3.839   Cond. No.                         33.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<p>Below is a simple visual check on if there is manipulation of groups around the cutoff point</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">][</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;treatment&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Below Cutoff&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">][</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;treatment&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Above Cutoff&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Running Variable&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Running Variable Distribution by Treatment&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cf176cfe825b8c5cc340201855ea102c33c65a90321541dd118fd01841fa330a.png" src="../_images/cf176cfe825b8c5cc340201855ea102c33c65a90321541dd118fd01841fa330a.png" />
</div>
</div>
</section>
</section>
<section id="path-forward">
<h2><span class="section-number">11.6. </span>Path Forward<a class="headerlink" href="#path-forward" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>More on Regression Discontinuity</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./sections"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="10_Instruments.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">10. </span>Instrumental Variables</p>
      </div>
    </a>
    <a class="right-next"
       href="12_RDD.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">12. </span>Instrumental Variables (Continued) and Intro to Regression Discontinuity (RDD)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recap-from-last-class">11.1. Recap From Last Class</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals-for-today">11.2. Goals For Today</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">11.3. 2. Instrumental Variables (Continued)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#revisit-the-effect-of-watching-sesame-street-on-later-academic-achievement">11.3.1. Revisit - The effect of watching sesame street on later academic achievement.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data">11.3.2. Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduced-form">11.3.3. “Reduced Form”</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#remember-non-compliance-and-itt">11.3.3.1. <strong>Remember non-compliance and ITT?</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weak-instrument">11.3.4. Weak Instrument</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">11.3.5. Estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#via-the-explicit-two-stage-least-squares-2sls-estimation">11.3.5.1. Via the (explicit) Two-Stage Least Squares (2SLS) Estimation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#via-the-iv2sls-function-from-linearmodels">11.3.5.2. Via the IV2SLS Function from linearmodels</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instrument-with-control">11.3.6. Instrument with Control</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#colider-bias">11.4. 3. Colider Bias</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-regression-discontinuity">11.5. 4. Introduction to Regression Discontinuity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#major-assumption">11.5.1. Major Assumption</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">11.5.2. Estimation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#path-forward">11.6. Path Forward</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Daniela Pinto Veizaga, Xiang Pan, and Xiang Gao
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>