{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQLNpzhJBsjA"
   },
   "source": [
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dapivei/causal-infere/blob/main/sections/8_ML_and_Causality.ipynb)\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsLZI9CzzVrf"
   },
   "source": [
    "# The Interplay between Machine Learning and Causal Inference\n",
    "\n",
    "There is an increasing interest in  \n",
    "\n",
    "1.   how machine learning techniques can improve causal effect estimation\n",
    "2.   how causal inference principles can enhance machine learning algorithms, particularly for robustness\n",
    "\n",
    "The aim of this lab is to give you a broad overview of existing work and research at the intersection of machine learning and causal inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdORTKzfx289"
   },
   "source": [
    "## 1. Machine Learning for Causality\n",
    "\n",
    "The first step in performing causal inference is knowing the causal parameter we are trying to identify and estimate. In this class, we have been mostly focused on the average treatment effect (ATE):\n",
    "\n",
    "\\begin{equation}\n",
    "ATE = \\mathbb{E}[Y(1, U) - Y(0, U)]\n",
    "\\end{equation}\n",
    "\n",
    "We can identify the above equation to form a statistical estimand by conditioning if $S \\perp U$:\n",
    "\n",
    "\\begin{equation}\n",
    "ATE = \\mathbb{E}[Y(1, U)|S=1] - \\mathbb{E}[Y(0, U)|S=0]\n",
    "\\end{equation}\n",
    "\n",
    "Last week, we also learned that the identification of ATE can be facilitated through conditional independence.\n",
    "\n",
    "\\begin{equation}\n",
    "S \\perp U \\ | \\ C\n",
    "\\end{equation}\n",
    "\n",
    "Remember, we cannot just make any (machine-learning) models as being \"causal\" models, but we know the conditions and assumptions under which causality is feasible: descriptive regression $→$ causal regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoUhXIS8hhql"
   },
   "source": [
    "### 1.1 Other Causal Parameters?\n",
    "\n",
    "Actually, you have seen another causal parameter: individualized treatment effect (ITE). It is the most straightforward to write down, but it is also the most difficult one (almost impossible) to identify. Instead of estimating causal effects on a population level, the inidividual level effect is much more helpful as it underpins the promises of things like personalized medicine (one medication could be helpful on average but harmful for a particular individual).\n",
    "\n",
    "\\begin{equation}\n",
    "ITE = Y_i(1, u) - Y_i(0, u)\n",
    "\\end{equation}\n",
    "\n",
    "Instead, an easier quantity to learn is called conditional average treatment effect (CATE). For the rest of the lab, we will use a more standard machine learning notation involving $(Y, X, T)$ and not writing $U$ for simplicity.\n",
    "\n",
    "\\begin{equation}\n",
    "CATE = \\mathbb{E}[Y(1) - Y(0) | X]\n",
    "\\end{equation}\n",
    "\n",
    "If we are simply leveraging the conditional independence assumption for identifying ATE, this can be written as the following:\n",
    "\n",
    "\\begin{equation}\n",
    "ATE = \\mathbb{E}_{X}\\left[\\mathbb{E}[Y(1) - Y(0) | X]\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-FNDUA42Too"
   },
   "source": [
    "### 1.2 Statistical Estimands\n",
    "\n",
    "Given a dataset of $D = \\{Y, X, T\\}$, we can identify the above ATE and CATE with two major assumptions:\n",
    "\n",
    "\n",
    "1. Ignorability: $Y(1), Y(0) \\perp T | X$\n",
    "2. Positivity: $p(T=t | X = \\mathbf{x}) >0, ∀t, \\mathbf{x}$\n",
    "\n",
    "We have seen the first one! It reads as the treatment assignment does not influence the potential outcomes condition on the features $X$, i.e., the treatment group and the control group should have similar characteristics ($S \\perp U | C$).\n",
    "\n",
    "We haven't talked much about positivity yet as we are just beginning to touch on control variables, but this is intuitive: there always should be people taking all the treatment options among the subpopulation on which they are conditioned. For example, if all college graduates do not attend the job training program, this assumption will be violated.\n",
    "\n",
    "We can derive the statistical estimand for CATE and ATE just as in lectures.\n",
    "\n",
    "\\begin{align}\n",
    "CATE &= \\mathbb{E}[Y(1) - Y(0) | X] \\\\\n",
    "&= \\mathbb{E}[Y(1)|X] - \\mathbb{E}[Y(0) | X] \\\\\n",
    "&= \\mathbb{E}[Y(1)|T=1, X] - \\mathbb{E}[Y(0) |T=0, X] \\\\\n",
    "&= \\mathbb{E}[Y|T=1, X] - \\mathbb{E}[Y|T=0, X] \\\\\n",
    "\\end{align}\n",
    "\n",
    "and,\n",
    "\n",
    "\\begin{align}\n",
    "ATE &= \\mathbb{E}_{X}\\left[\\mathbb{E}[Y(1) - Y(0) | X]\\right] \\\\\n",
    "&= \\mathbb{E}_{X}\\left[\\mathbb{E}[Y|T=1, X] - \\mathbb{E}[Y|T=0, X]\\right] \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qa2tK4Xz4BcR"
   },
   "source": [
    "### 1.3 Advanced Estimation\n",
    "\n",
    "When the assumptions hold, we can simply regress the outcome on the treatment and features, and we have shown in class that the coefficient for the treatment variable is the corresponding ATE. For CATE, we can add an interaction term between treatment and the conditioned feature like $\\beta XT$.\n",
    "\n",
    "However, what if the underlying true model is **not** a linear model?\n",
    "\n",
    "In general, we can use any model class for estimating $\\mathbb{E}[Y|T=1, X]$ and $\\mathbb{E}[Y|T=0, X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jTd1RmXIgt8"
   },
   "source": [
    "#### 1.3.1 S-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vZqaoAaHqpK"
   },
   "source": [
    "We can use a single model $f(\\mathbf{x}_i, t_i)$ to predict $Y$ based on $X$ and $T$.\n",
    "\n",
    "![S-learner](https://github.com/dapivei/causal-infere/blob/main/sections/images/S-learner.png?raw=true)\n",
    "\n",
    "image credit: [link](https://csc2541-2022.github.io/lectures/CSC2541_lecture4_estimation.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vkalx8NHrSB"
   },
   "source": [
    "Let's simulate some data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-sDFhIYqGYF7",
    "outputId": "2dc075e7-8c7d-4000-83f1-7eecb48f8cd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"X1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0179981717991133,\n        \"min\": -3.9224002516183423,\n        \"max\": 3.9262377064363267,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -2.241915934508913,\n          -0.7194723843379374,\n          1.1262381884363837\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9936715194751412,\n        \"min\": -3.688365291428444,\n        \"max\": 3.9423310108066856,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          0.20545568703630285,\n          -0.6251074206936527,\n          -0.24039847568841113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0021227345364339,\n        \"min\": -3.635200227540102,\n        \"max\": 3.152056734512085,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.7756066046023912,\n          0.9431592010001667,\n          0.7678436946681114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9919194616520737,\n        \"min\": -3.3078999524973884,\n        \"max\": 4.479084251025757,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.8003354061653037,\n          -0.008870932289573393,\n          -0.19458466303966782\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"X5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9864707995113263,\n        \"min\": -3.856375329240597,\n        \"max\": 3.852731490654721,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          -0.49898725597911187,\n          1.133688498098509,\n          0.033870549435244236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0319701006110806,\n        \"min\": -7.6790193059627505,\n        \"max\": 9.933772064006464,\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          0.816336970088291,\n          -2.3469479616593336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5571563b-90b7-457a-be10-c41505691594\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496714</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.647689</td>\n",
       "      <td>1.523030</td>\n",
       "      <td>-0.234153</td>\n",
       "      <td>1</td>\n",
       "      <td>1.145004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.234137</td>\n",
       "      <td>1.579213</td>\n",
       "      <td>0.767435</td>\n",
       "      <td>-0.469474</td>\n",
       "      <td>0.542560</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.081058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.463418</td>\n",
       "      <td>-0.465730</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>-1.913280</td>\n",
       "      <td>-1.724918</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.284728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.562288</td>\n",
       "      <td>-1.012831</td>\n",
       "      <td>0.314247</td>\n",
       "      <td>-0.908024</td>\n",
       "      <td>-1.412304</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.214069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.465649</td>\n",
       "      <td>-0.225776</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>-1.424748</td>\n",
       "      <td>-0.544383</td>\n",
       "      <td>0</td>\n",
       "      <td>1.651123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5571563b-90b7-457a-be10-c41505691594')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5571563b-90b7-457a-be10-c41505691594 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5571563b-90b7-457a-be10-c41505691594');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b67db53f-4060-4fe1-b03f-9e4fb5b4363d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b67db53f-4060-4fe1-b03f-9e4fb5b4363d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b67db53f-4060-4fe1-b03f-9e4fb5b4363d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5  T         Y\n",
       "0  0.496714 -0.138264  0.647689  1.523030 -0.234153  1  1.145004\n",
       "1 -0.234137  1.579213  0.767435 -0.469474  0.542560  1 -0.081058\n",
       "2 -0.463418 -0.465730  0.241962 -1.913280 -1.724918  0 -1.284728\n",
       "3 -0.562288 -1.012831  0.314247 -0.908024 -1.412304  1 -1.214069\n",
       "4  1.465649 -0.225776  0.067528 -1.424748 -0.544383  0  1.651123"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# simulate features\n",
    "np.random.seed(42)\n",
    "n = 5000\n",
    "X = np.random.normal(0, 1, (n, 5))\n",
    "\n",
    "# simulate treatment assignment (binary treatment)\n",
    "T = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "# define true treatment effect function\n",
    "def true_effect(x):\n",
    "    return 2 * x[:, 0]\n",
    "\n",
    "# simulate outcomes\n",
    "Y = true_effect(X) * T + X[:, 1] + np.random.normal(0, 1, n)\n",
    "\n",
    "# create a DataFrame\n",
    "data = pd.DataFrame(X, columns=[f'X{i}' for i in range(1, 6)])\n",
    "data['T'] = T\n",
    "data['Y'] = Y\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CiryhGYD6uBH"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features and target\n",
    "X_all = data.drop('Y', axis=1)\n",
    "y_all = data['Y']\n",
    "\n",
    "# perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# separate T and X in training and test sets\n",
    "T_train = X_train['T']\n",
    "X_train_features = X_train.drop('T', axis=1)\n",
    "\n",
    "T_test = X_test['T']\n",
    "X_test_features = X_test.drop('T', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LuNgNWTzIhNT",
    "outputId": "80505e00-e637-4d86-f3ed-f10215852951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE using S-Learner: -0.0193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# include T in the features\n",
    "X_train_s = X_train.copy()\n",
    "y_train_s = y_train.copy()\n",
    "\n",
    "# train the S-Learner\n",
    "model_s = RandomForestRegressor(random_state=42)\n",
    "model_s.fit(X_train_s, y_train_s)\n",
    "\n",
    "# prepare test data with T=1 and T=0\n",
    "X_test_T1 = X_test.copy()\n",
    "X_test_T1['T'] = 1\n",
    "\n",
    "X_test_T0 = X_test.copy()\n",
    "X_test_T0['T'] = 0\n",
    "\n",
    "# predict outcomes\n",
    "y_pred_T1 = model_s.predict(X_test_T1)\n",
    "y_pred_T0 = model_s.predict(X_test_T0)\n",
    "\n",
    "# estimate ITE\n",
    "ite_s = y_pred_T1 - y_pred_T0\n",
    "\n",
    "# compute ATE\n",
    "ate_s = np.mean(ite_s)\n",
    "\n",
    "print(f\"Estimated ATE using S-Learner: {ate_s:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87MFEtEi24aH"
   },
   "source": [
    "What are some potential problems if we have high-dimensional $X$, i.e., $D$ is very large?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v4BxFgmJHkb"
   },
   "source": [
    "#### 1.3.2 T-learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeQhgiBH3RbV"
   },
   "source": [
    "Alternatively, we can build separate models $f_1(\\mathbf{x}_i, T=1)$ and $f_0(\\mathbf{x}_i, T=0)$ for the treatment and control group.\n",
    "\n",
    "![T-learner](https://github.com/dapivei/causal-infere/blob/main/sections/images/T-learner.png?raw=true)\n",
    "\n",
    "image credit: [link](https://csc2541-2022.github.io/lectures/CSC2541_lecture4_estimation.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1JU0pIx4ALS",
    "outputId": "785502dd-c064-4c51-babb-5fb3f5052275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE using T-Learner: -0.0338\n"
     ]
    }
   ],
   "source": [
    "# split training data by treatment\n",
    "train_data = X_train.copy()\n",
    "train_data['Y'] = y_train\n",
    "\n",
    "train_treated = train_data[train_data['T'] == 1]\n",
    "train_control = train_data[train_data['T'] == 0]\n",
    "\n",
    "# features and target for treated group\n",
    "X_treated = train_treated.drop(['Y', 'T'], axis=1)\n",
    "y_treated = train_treated['Y']\n",
    "\n",
    "# features and target for control group\n",
    "X_control = train_control.drop(['Y', 'T'], axis=1)\n",
    "y_control = train_control['Y']\n",
    "\n",
    "# train models\n",
    "model_treated = RandomForestRegressor(random_state=42)\n",
    "model_control = RandomForestRegressor(random_state=42)\n",
    "\n",
    "model_treated.fit(X_treated, y_treated)\n",
    "model_control.fit(X_control, y_control)\n",
    "\n",
    "# predict outcomes on test set\n",
    "y_pred_treated = model_treated.predict(X_test_features)\n",
    "y_pred_control = model_control.predict(X_test_features)\n",
    "\n",
    "# estimate ITE\n",
    "ite_t = y_pred_treated - y_pred_control\n",
    "\n",
    "# compute ATE\n",
    "ate_t = np.mean(ite_t)\n",
    "\n",
    "print(f\"Estimated ATE using T-Learner: {ate_t:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6ScPxzv-Psf"
   },
   "source": [
    "#### 1.3.3 TAR-Net\n",
    "\n",
    "What are some of the drawbacks of the above approaches?\n",
    "\n",
    "![Tradeoff](https://github.com/dapivei/causal-infere/blob/main/images/Trade-off.png?raw=true)\n",
    "\n",
    "[Johansson, Shalit, and Sontag, 2016](https://arxiv.org/abs/1606.03976) leveraged neural networks to overcome the above challenge via learning a common representation.\n",
    "\n",
    "(Additional regularization needed to ensure balanced representations for both groups)\n",
    "\n",
    "![TAR-Net](https://github.com/dapivei/causal-infere/blob/main/images/TAR-Net.png?raw=true)\n",
    "\n",
    "image credit: [link](https://csc2541-2022.github.io/lectures/CSC2541_lecture4_estimation.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UHxQ4BPJ-ZLq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# prepare training data tensors\n",
    "X_train_tensor = torch.tensor(X_train_features.values, dtype=torch.float32)\n",
    "T_train_tensor = torch.tensor(T_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "Y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, T_train_tensor, Y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# define TARNet model\n",
    "class TARNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TARNet, self).__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.outcome_0 = nn.Sequential(\n",
    "            nn.Linear(100, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "        self.outcome_1 = nn.Sequential(\n",
    "            nn.Linear(100, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        phi = self.shared(x)\n",
    "        y0 = self.outcome_0(phi)\n",
    "        y1 = self.outcome_1(phi)\n",
    "        y_pred = t * y1 + (1 - t) * y0\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, x):\n",
    "        phi = self.shared(x)\n",
    "        y0 = self.outcome_0(phi)\n",
    "        y1 = self.outcome_1(phi)\n",
    "        return y0, y1\n",
    "\n",
    "# initialize model, loss function, and optimizer\n",
    "model = TARNet(input_dim=5)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SjRrzL_AL0f",
    "outputId": "89c34a40-9b59-40aa-8a7c-5e4d01a9fdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.0349\n",
      "Epoch 10, Loss: 1.0132\n",
      "Epoch 15, Loss: 1.0015\n",
      "Epoch 20, Loss: 0.9859\n",
      "Epoch 25, Loss: 0.9719\n",
      "Epoch 30, Loss: 0.9615\n",
      "Epoch 35, Loss: 0.9574\n",
      "Epoch 40, Loss: 0.9332\n",
      "Epoch 45, Loss: 0.9291\n",
      "Epoch 50, Loss: 0.9166\n",
      "Epoch 55, Loss: 0.9037\n",
      "Epoch 60, Loss: 0.8932\n",
      "Epoch 65, Loss: 0.8889\n",
      "Epoch 70, Loss: 0.8796\n",
      "Epoch 75, Loss: 0.8734\n",
      "Epoch 80, Loss: 0.8613\n",
      "Epoch 85, Loss: 0.8584\n",
      "Epoch 90, Loss: 0.8423\n",
      "Epoch 95, Loss: 0.8357\n",
      "Epoch 100, Loss: 0.8344\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, T_batch, Y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch, T_batch)\n",
    "        loss = criterion(y_pred, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UOm7wgWAPQ6",
    "outputId": "87bd5b5e-265d-4129-c775-c95eae9cf8ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ATE using TARNet: -0.0584\n"
     ]
    }
   ],
   "source": [
    "# prepare test data tensors\n",
    "X_test_tensor = torch.tensor(X_test_features.values, dtype=torch.float32)\n",
    "\n",
    "# estimate ITE\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0_pred, y1_pred = model.predict(X_test_tensor)\n",
    "    ite_tar = (y1_pred - y0_pred).numpy().flatten()\n",
    "\n",
    "# compute ATE\n",
    "ate_tar = np.mean(ite_tar)\n",
    "\n",
    "print(f\"Estimated ATE using TARNet: {ate_tar:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rn4NBWTCJP4B",
    "outputId": "8f80453e-a548-4e81-d85d-1dd97c641c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ATE:    -0.0276\n"
     ]
    }
   ],
   "source": [
    "# Compute true ATE\n",
    "X_test_array = X_test_features.values\n",
    "true_ite = true_effect(X_test_array)\n",
    "true_ate = np.mean(true_ite)\n",
    "print(f\"True ATE:    {true_ate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_UkNVoB8JJU"
   },
   "source": [
    "### 1.3.4 Double Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqQe5p5qCCkk"
   },
   "source": [
    "TAR-Net still suffers a few problems:\n",
    "\n",
    "\n",
    "*   does not support other machine learning models\n",
    "*   only applies to binary treatment\n",
    "*   no uncertainty quantification\n",
    "\n",
    "Double ML provides a framework that leverage general machine learning models to obtain **unbiased** causal effect estimates with *fast convergence* and *confidence intervals*, and it is still among the best methods in causal effect estimation. (You just need to know such a method exists. Further reading: [link](https://econml.azurewebsites.net/spec/estimation/dml.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBtUTVEY86Xj"
   },
   "source": [
    "## 2. Causal Inference for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmXWMh15KXWh"
   },
   "source": [
    "We will not go into technical detail in this section but aim to provide you with a high-level intuition on how causality can help predictions.\n",
    "\n",
    "The standard machine-learning pipeline assumes that the test examples are I.I.D as the training data distribution. However, in practice, this is often violated. For instance, we train an imaging model to read CT scans using data from NYU Langone, will this model do well if it is deployed in other countries w. different imaging equipment and lighting conditions?\n",
    "\n",
    "![OOD-eg](https://github.com/dapivei/causal-infere/blob/main/images/OOD.png?raw=true)\n",
    "\n",
    "image credit: [link](https://arxiv.org/abs/1911.08731)\n",
    "\n",
    "We hope to build models that are robust to changes to test distribution, i.e., achieving out-of-distribution generalization. Why is this difficult?\n",
    "\n",
    "During training, the model can easily pick up on predictive signals from features that are relevant in distribution, e.g., image background. This relationship will not hold in other data distributions.\n",
    "\n",
    "However, causal relationships are reliable associations across different distributions. We can formalize it through causality so that we can build models that only rely on causal features/representations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
